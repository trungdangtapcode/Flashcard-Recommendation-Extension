{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10319203,"sourceType":"datasetVersion","datasetId":6388820},{"sourceId":10319228,"sourceType":"datasetVersion","datasetId":6388835},{"sourceId":10319313,"sourceType":"datasetVersion","datasetId":6388891}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:19:54.913309Z","iopub.execute_input":"2024-12-30T05:19:54.913600Z","iopub.status.idle":"2024-12-30T05:19:54.920747Z","shell.execute_reply.started":"2024-12-30T05:19:54.913576Z","shell.execute_reply":"2024-12-30T05:19:54.919858Z"}},"outputs":[{"name":"stdout","text":"/kaggle\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install fastapi nest-asyncio pyngrok uvicorn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:19:54.921883Z","iopub.execute_input":"2024-12-30T05:19:54.922143Z","iopub.status.idle":"2024-12-30T05:20:00.300000Z","shell.execute_reply.started":"2024-12-30T05:19:54.922123Z","shell.execute_reply":"2024-12-30T05:20:00.298953Z"}},"outputs":[{"name":"stdout","text":"Collecting fastapi\n  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\nCollecting pyngrok\n  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\nCollecting uvicorn\n  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting starlette<0.42.0,>=0.40.0 (from fastapi)\n  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.9.2)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\nCollecting h11>=0.8 (from uvicorn)\n  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\nRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\nDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\nDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyngrok, h11, uvicorn, starlette, fastapi\nSuccessfully installed fastapi-0.115.6 h11-0.14.0 pyngrok-7.2.2 starlette-0.41.3 uvicorn-0.34.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -U timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:00.301904Z","iopub.execute_input":"2024-12-30T05:20:00.302209Z","iopub.status.idle":"2024-12-30T05:20:03.515641Z","shell.execute_reply.started":"2024-12-30T05:20:00.302187Z","shell.execute_reply":"2024-12-30T05:20:03.514549Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.12)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install torchscale","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:03.517207Z","iopub.execute_input":"2024-12-30T05:20:03.517469Z","iopub.status.idle":"2024-12-30T05:20:16.951505Z","shell.execute_reply.started":"2024-12-30T05:20:03.517448Z","shell.execute_reply":"2024-12-30T05:20:16.950654Z"}},"outputs":[{"name":"stdout","text":"Collecting torchscale\n  Downloading torchscale-0.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from torchscale) (2.4.1+cu121)\nCollecting fairscale==0.4.0 (from torchscale)\n  Downloading fairscale-0.4.0.tar.gz (190 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting timm==0.6.13 (from torchscale)\n  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.6.13->torchscale) (0.19.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.6.13->torchscale) (6.0.2)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.6.13->torchscale) (0.24.7)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.13->torchscale) (24.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.13->torchscale) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.13->torchscale) (4.66.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->torchscale) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->torchscale) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.6.13->torchscale) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.6.13->torchscale) (10.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale) (2024.8.30)\nDownloading torchscale-0.3.0-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.6.13-py3-none-any.whl (549 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: fairscale\n  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fairscale: filename=fairscale-0.4.0-py3-none-any.whl size=239917 sha256=38d587b11068d3033deec7c3f210cd5392fd3ee90bbae42b98dc993634003b6f\n  Stored in directory: /root/.cache/pip/wheels/5e/3d/e9/3995d67ff23a09f72bba6380efb35ba97091c7932748884c41\nSuccessfully built fairscale\nInstalling collected packages: fairscale, timm, torchscale\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.12\n    Uninstalling timm-1.0.12:\n      Successfully uninstalled timm-1.0.12\nSuccessfully installed fairscale-0.4.0 timm-0.6.13 torchscale-0.3.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom PIL import Image\nimport glob\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:16.952475Z","iopub.execute_input":"2024-12-30T05:20:16.952690Z","iopub.status.idle":"2024-12-30T05:20:19.833365Z","shell.execute_reply.started":"2024-12-30T05:20:16.952672Z","shell.execute_reply":"2024-12-30T05:20:19.832703Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from torchvision.datasets.folder import default_loader\nfrom torchvision import transforms\nimport os\nfrom timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_INCEPTION_MEAN, IMAGENET_INCEPTION_STD","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:19.834246Z","iopub.execute_input":"2024-12-30T05:20:19.834657Z","iopub.status.idle":"2024-12-30T05:20:23.244362Z","shell.execute_reply.started":"2024-12-30T05:20:19.834626Z","shell.execute_reply":"2024-12-30T05:20:23.243400Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!wget https://github.com/addf400/files/releases/download/beit3/beit3_large_patch16_384_coco_retrieval.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:23.245357Z","iopub.execute_input":"2024-12-30T05:20:23.245571Z","iopub.status.idle":"2024-12-30T05:20:27.649593Z","shell.execute_reply.started":"2024-12-30T05:20:23.245551Z","shell.execute_reply":"2024-12-30T05:20:27.648617Z"}},"outputs":[{"name":"stdout","text":"--2024-12-30 05:20:23--  https://github.com/addf400/files/releases/download/beit3/beit3_large_patch16_384_coco_retrieval.pth\nResolving github.com (github.com)... 140.82.116.4\nConnecting to github.com (github.com)|140.82.116.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/717694328/12181991-ee94-4e2d-a56f-2458d50cf7b7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241230%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241230T052023Z&X-Amz-Expires=300&X-Amz-Signature=e8c00a2499c8a65d2cf3ce94fdc83c8438edb0e3caf5fc47b39204fb1c8f07ab&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dbeit3_large_patch16_384_coco_retrieval.pth&response-content-type=application%2Foctet-stream [following]\n--2024-12-30 05:20:23--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/717694328/12181991-ee94-4e2d-a56f-2458d50cf7b7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241230%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241230T052023Z&X-Amz-Expires=300&X-Amz-Signature=e8c00a2499c8a65d2cf3ce94fdc83c8438edb0e3caf5fc47b39204fb1c8f07ab&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dbeit3_large_patch16_384_coco_retrieval.pth&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1350590595 (1.3G) [application/octet-stream]\nSaving to: ‘beit3_large_patch16_384_coco_retrieval.pth’\n\nbeit3_large_patch16 100%[===================>]   1.26G   349MB/s    in 3.8s    \n\n2024-12-30 05:20:27 (343 MB/s) - ‘beit3_large_patch16_384_coco_retrieval.pth’ saved [1350590595/1350590595]\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nfrom timm.models.layers import trunc_normal_ as __call_trunc_normal_\nfrom timm.models.registry import register_model\nimport torch.nn.functional as F\nimport numpy as np\n\nfrom torchscale.model.BEiT3 import BEiT3\nfrom torchscale.architecture.config import EncoderConfig\n# import utils\n\ndef trunc_normal_(tensor, mean=0., std=1.):\n    __call_trunc_normal_(tensor, mean=mean, std=std, a=-std, b=std)\n\n\ndef _get_base_config(\n        img_size=384, patch_size=16, drop_path_rate=0, \n        checkpoint_activations=None, mlp_ratio=4, vocab_size=64010, **kwargs\n):\n    return EncoderConfig(\n        img_size=img_size, patch_size=patch_size, vocab_size=vocab_size, multiway=True, \n        layernorm_embedding=False, normalize_output=True, no_output_layer=True, \n        drop_path_rate=drop_path_rate, encoder_embed_dim=768, encoder_attention_heads=12, \n        encoder_ffn_embed_dim=int(768 * mlp_ratio), encoder_layers=12, \n        checkpoint_activations=checkpoint_activations, \n    )\n\n\ndef _get_large_config(\n        img_size=384, patch_size=16, drop_path_rate=0, \n        checkpoint_activations=None, mlp_ratio=4, vocab_size=64010, **kwargs\n):\n    return EncoderConfig(\n        img_size=img_size, patch_size=patch_size, vocab_size=vocab_size, multiway=True, \n        layernorm_embedding=False, normalize_output=True, no_output_layer=True, \n        drop_path_rate=drop_path_rate, encoder_embed_dim=1024, encoder_attention_heads=16, \n        encoder_ffn_embed_dim=int(1024 * mlp_ratio), encoder_layers=24, \n        checkpoint_activations=checkpoint_activations, \n    )\n\n\nclass BEiT3Wrapper(nn.Module):\n    def __init__(self, args, **kwargs):\n        super().__init__()\n        self.args = args\n        self.beit3 = BEiT3(args)\n        self.apply(self._init_weights)\n\n    def fix_init_weight(self):\n        def rescale(param, layer_id):\n            param.div_(math.sqrt(2.0 * layer_id))\n\n        for layer_id, layer in enumerate(self.blocks):\n            rescale(layer.attn.proj.weight.data, layer_id + 1)\n            rescale(layer.mlp.fc2.weight.data, layer_id + 1)\n\n    def get_num_layers(self):\n        return self.beit3.encoder.num_layers\n\n    @torch.jit.ignore\n    def no_weight_decay(self):\n        return {'pos_embed', 'cls_token', 'beit3.encoder.embed_positions.A.weight', 'beit3.vision_embed.cls_token', 'logit_scale'}\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            trunc_normal_(m.weight, std=.02)\n            if isinstance(m, nn.Linear) and m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.constant_(m.bias, 0)\n            nn.init.constant_(m.weight, 1.0)\n\n\nclass BEiT3ForRetrieval(BEiT3Wrapper):\n    def __init__(\n            self, \n            args,\n            **kwargs\n    ):\n        super(BEiT3ForRetrieval, self).__init__(args=args)\n        embed_dim = args.encoder_embed_dim\n        self.language_head = nn.Linear(embed_dim, embed_dim, bias=False)\n        self.vision_head = nn.Linear(embed_dim, embed_dim, bias=False)\n        self.language_head.apply(self._init_weights)\n        self.vision_head.apply(self._init_weights)\n        self.criterion = None\n#         self.criterion = utils.ClipLoss(\n#             rank=utils.get_rank(), \n#             world_size=utils.get_world_size(), \n#         )\n        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n\n    def forward(self, image=None, text_description=None, padding_mask=None, only_infer=False, **kwargs):\n        if image is not None:\n            outputs = self.beit3(\n                textual_tokens=None, \n                visual_tokens=image, \n                text_padding_position=None, \n            )\n            x = outputs[\"encoder_out\"]\n            vision_cls = self.vision_head(x[:, 0, :])\n            vision_cls = F.normalize(vision_cls, dim=-1)\n        else:\n            vision_cls = None\n\n        if text_description is not None:\n            outputs = self.beit3(\n                textual_tokens=text_description, \n                visual_tokens=None, \n                text_padding_position=padding_mask, \n            )\n            x = outputs[\"encoder_out\"]\n            language_cls = self.language_head(x[:, 0, :])\n            language_cls = F.normalize(language_cls, dim=-1)\n        else:\n            language_cls = None\n        \n        if only_infer:\n            return vision_cls, language_cls\n        else:\n            loss, logits_per_image, logits_per_text = self.criterion(\n                vision_cls, language_cls, self.logit_scale.exp())\n            return loss, vision_cls, language_cls\n\n\n@register_model\ndef beit3_large_patch16_384_retrieval(pretrained=False, **kwargs):\n    args = _get_large_config(img_size=384, **kwargs)\n    model = BEiT3ForRetrieval(args, **kwargs)\n    return model\n\n@register_model\ndef beit3_base_patch16_384_retrieval(pretrained=False, **kwargs):\n    args = _get_base_config(img_size=384, **kwargs)\n    model = BEiT3ForRetrieval(args, **kwargs)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:27.652292Z","iopub.execute_input":"2024-12-30T05:20:27.652563Z","iopub.status.idle":"2024-12-30T05:20:27.710115Z","shell.execute_reply.started":"2024-12-30T05:20:27.652540Z","shell.execute_reply":"2024-12-30T05:20:27.709480Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def get_sentencepiece_model_for_beit3(model_path):\n    from transformers import XLMRobertaTokenizer\n    return XLMRobertaTokenizer(model_path)\n\ndef to_text_tokens(text, tokenizer, max_len = 64):\n\n    tokens_orig = tokenizer.tokenize(text)\n    token_ids = tokenizer.convert_tokens_to_ids(tokens_orig)\n    tokens = token_ids\n\n    if len(tokens) > max_len - 2:\n        tokens = tokens[:max_len - 2]\n\n    tokens = [tokenizer.bos_token_id] + tokens[:] + [tokenizer.eos_token_id]\n    num_tokens = len(tokens)\n    padding_mask = [0] * num_tokens + [1] * (max_len - num_tokens)\n    tokens_true = tokens + [tokenizer.pad_token_id] * (max_len - num_tokens)\n\n    padding_mask_tensor = torch.tensor(padding_mask).reshape(1, -1)\n    token_ids_tensor = torch.tensor(tokens_true).reshape(1, -1)\n    \n    return token_ids_tensor, padding_mask_tensor\n\ndef calc_text_embedding(text, tokenizer):\n    text_tokens, padding_mask = to_text_tokens(text, tokenizer)\n    text_tokens = text_tokens.to('cuda:0')\n    padding_mask = padding_mask.to('cuda:0')\n    text_embedding = model(text_description=text_tokens, padding_mask=padding_mask, only_infer=True)\n    return text_embedding[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:27.711503Z","iopub.execute_input":"2024-12-30T05:20:27.712091Z","iopub.status.idle":"2024-12-30T05:20:27.718165Z","shell.execute_reply.started":"2024-12-30T05:20:27.712069Z","shell.execute_reply":"2024-12-30T05:20:27.717287Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nimport timm\n\nmodel_name = \"beit3_large_patch16_384_retrieval\"  # Replace with the specific model you want to use, e.g., \"resnet50\", \"efficientnet_b3\", etc.\nnum_classes = 10  # Replace with the number of output classes in your model\n\nmodel = timm.models.create_model(model_name, pretrained=False, num_classes=num_classes)\n\nckpt_path = \"beit3_large_patch16_384_coco_retrieval.pth\"\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ncheckpoint = torch.load(ckpt_path, map_location=device)\n# print(checkpoint)\n\ntokenizer = get_sentencepiece_model_for_beit3('/kaggle/input/beit3-spm/beit3.spm')\n\n# Step 4: Load the model weights from the checkpoint\nmodel.load_state_dict(checkpoint['model'])\n\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:27.719064Z","iopub.execute_input":"2024-12-30T05:20:27.719352Z","iopub.status.idle":"2024-12-30T05:20:42.439544Z","shell.execute_reply.started":"2024-12-30T05:20:27.719324Z","shell.execute_reply":"2024-12-30T05:20:42.438776Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-10-744777e5994d>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(ckpt_path, map_location=device)\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"BEiT3ForRetrieval(\n  (beit3): BEiT3(\n    (text_embed): TextEmbedding(64010, 1024)\n    (vision_embed): VisionEmbedding(\n      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (encoder): Encoder(\n      (dropout_module): Dropout(p=0.0, inplace=False)\n      (embed_positions): MutliwayEmbedding(\n        (A): PositionalEmbedding(579, 1024)\n        (B): PositionalEmbedding(1024, 1024)\n      )\n      (layers): ModuleList(\n        (0-23): 24 x EncoderLayer(\n          (self_attn): MultiheadAttention(\n            (k_proj): MultiwayNetwork(\n              (A): Linear(in_features=1024, out_features=1024, bias=True)\n              (B): Linear(in_features=1024, out_features=1024, bias=True)\n            )\n            (v_proj): MultiwayNetwork(\n              (A): Linear(in_features=1024, out_features=1024, bias=True)\n              (B): Linear(in_features=1024, out_features=1024, bias=True)\n            )\n            (q_proj): MultiwayNetwork(\n              (A): Linear(in_features=1024, out_features=1024, bias=True)\n              (B): Linear(in_features=1024, out_features=1024, bias=True)\n            )\n            (out_proj): MultiwayNetwork(\n              (A): Linear(in_features=1024, out_features=1024, bias=True)\n              (B): Linear(in_features=1024, out_features=1024, bias=True)\n            )\n            (inner_attn_ln): MultiwayNetwork(\n              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            )\n            (dropout_module): Dropout(p=0.0, inplace=False)\n          )\n          (self_attn_layer_norm): MultiwayNetwork(\n            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          )\n          (dropout_module): Dropout(p=0.0, inplace=False)\n          (ffn): MultiwayNetwork(\n            (A): FeedForwardNetwork(\n              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n              (dropout_module): Dropout(p=0.0, inplace=False)\n              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n            )\n            (B): FeedForwardNetwork(\n              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n              (dropout_module): Dropout(p=0.0, inplace=False)\n              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (final_layer_norm): MultiwayNetwork(\n            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n      )\n      (layer_norm): MultiwayNetwork(\n        (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (language_head): Linear(in_features=1024, out_features=1024, bias=False)\n  (vision_head): Linear(in_features=1024, out_features=1024, bias=False)\n)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# loading tje precomputed embeddings\nWORD_EMBEDDINGS = np.load('/kaggle/input/beit3-english-dictionary/BEIT3_word_embeddings.npy')\nWORD_MAPPING = np.load('/kaggle/input/beit3-english-dictionary/BEIT3_word_mapping.npy', allow_pickle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:42.440258Z","iopub.execute_input":"2024-12-30T05:20:42.440471Z","iopub.status.idle":"2024-12-30T05:20:46.706867Z","shell.execute_reply.started":"2024-12-30T05:20:42.440453Z","shell.execute_reply":"2024-12-30T05:20:46.706204Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(WORD_EMBEDDINGS.shape)\nprint(WORD_MAPPING.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:46.707703Z","iopub.execute_input":"2024-12-30T05:20:46.708013Z","iopub.status.idle":"2024-12-30T05:20:46.712881Z","shell.execute_reply.started":"2024-12-30T05:20:46.707983Z","shell.execute_reply":"2024-12-30T05:20:46.712050Z"}},"outputs":[{"name":"stdout","text":"(176009, 1024)\n(176009, 4)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"bio = \"\"\"\nMy profession and expertise are in UX/UI Designer, where I focus on Human-computer interaction,\n sustainable technology, and indie video game development. At 29 years old, I enjoy spending my free time on Digital painting, hiking, and playing board games, \n which help me unwind and stay inspired. I identify as Non-binary, and I am deeply passionate about Human-computer interaction, sustainable technology, and indie video game development\n , which drive much of my professional and personal growth. \n These interests fuel my curiosity and commitment to making a positive impact in my work and beyond.\n\"\"\"\n\nbio_emb = calc_text_embedding(bio, tokenizer).squeeze().detach().cpu().numpy() # (1024,)\n# bio_emb = bio_emb/np.linalg.norm(bio_emb)\n\n\nsimilarities = np.dot(WORD_EMBEDDINGS, bio_emb)\n\nsorted_indices = np.argsort(similarities)[::-1]\n\nsorted_similarities = [(WORD_MAPPING[idx], similarities[idx]) for idx in sorted_indices]\n\nfor word, similarity in sorted_similarities[:10]:\n    print(f\"{word}: {similarity:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:46.713515Z","iopub.execute_input":"2024-12-30T05:20:46.713726Z","iopub.status.idle":"2024-12-30T05:20:47.436623Z","shell.execute_reply.started":"2024-12-30T05:20:46.713708Z","shell.execute_reply":"2024-12-30T05:20:47.435905Z"}},"outputs":[{"name":"stdout","text":"['Conceptionalist' '15' '\"n.\"' '\"A conceptualist.\"']: 0.7902\n['Landscapist' '11' '\"n.\"' '\"A painter of landscapes.\"']: 0.7829\n['Designing' '9' '\"a.\"'\n '\"Intriguing; artful; scheming; as  a designing man.\"']: 0.7805\n['Designed' '8' '\"imp. & p. p.\"' '\"of Design\"']: 0.7803\n['Designing' '9' '\"p. pr. & vb. n.\"' '\"of Design\"']: 0.7803\n['Coadventurer' '12' '\"n.\"' '\"A fellow adventurer.\"']: 0.7785\n['Limner' '6' '\"n.\"' '\"A painter; an artist\"']: 0.7777\n['Engineered' '10' '\"imp. & p. p.\"' '\"of Engineer\"']: 0.7770\n['Engineering' '11' '\"p. pr. & vb. n.\"' '\"of Engineer\"']: 0.7770\n['Studier' '7' '\"n.\"' '\"A student.\"']: 0.7737\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from collections import Counter\n\ndef count_unique_words(sentence):\n    \"\"\"\n    Count the occurrences of each unique word in a sentence.\n    \n    Args:\n        sentence (str): The input sentence.\n    \n    Returns:\n        dict: A dictionary with words as keys and their counts as values.\n    \"\"\"\n    # Normalize the sentence by converting it to lowercase and splitting into words\n    words = sentence.lower().replace(\"!@#$%^&*()[]{};:,./<>?\\|`~-=_+\", \" \").split()\n    \n    # Count occurrences using Counter\n    word_counts = Counter(words)\n    \n    return dict(word_counts), len(words)\n\n# Câu ví dụ\nsentence = \"\"\"In this example, we walk through how you can combine retrieval results from multiple queries and multiple indexes.\nThe retrieved nodes will be reranked according to the Reciprocal Rerank Fusion algorithm demonstrated in this paper. It provides an effecient method for rerranking retrieval results without excessive computation or reliance on external models.\nA dictionary dataset that reflects American English as it's used today. The machine-readable format of the New Oxford American Dictionary provides more than 350,000 words and meanings, curated and annotated by our expert lexicographers.\"\"\"\n\n\nword_count = count_unique_words(sentence)\nprint(\"Word counts:\", word_count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:47.437361Z","iopub.execute_input":"2024-12-30T05:20:47.437568Z","iopub.status.idle":"2024-12-30T05:20:47.443169Z","shell.execute_reply.started":"2024-12-30T05:20:47.437550Z","shell.execute_reply":"2024-12-30T05:20:47.442506Z"}},"outputs":[{"name":"stdout","text":"Word counts: ({'in': 2, 'this': 2, 'example,': 1, 'we': 1, 'walk': 1, 'through': 1, 'how': 1, 'you': 1, 'can': 1, 'combine': 1, 'retrieval': 2, 'results': 2, 'from': 1, 'multiple': 2, 'queries': 1, 'and': 3, 'indexes.': 1, 'the': 4, 'retrieved': 1, 'nodes': 1, 'will': 1, 'be': 1, 'reranked': 1, 'according': 1, 'to': 1, 'reciprocal': 1, 'rerank': 1, 'fusion': 1, 'algorithm': 1, 'demonstrated': 1, 'paper.': 1, 'it': 1, 'provides': 2, 'an': 1, 'effecient': 1, 'method': 1, 'for': 1, 'rerranking': 1, 'without': 1, 'excessive': 1, 'computation': 1, 'or': 1, 'reliance': 1, 'on': 1, 'external': 1, 'models.': 1, 'a': 1, 'dictionary': 2, 'dataset': 1, 'that': 1, 'reflects': 1, 'american': 2, 'english': 1, 'as': 1, \"it's\": 1, 'used': 1, 'today.': 1, 'machine-readable': 1, 'format': 1, 'of': 1, 'new': 1, 'oxford': 1, 'more': 1, 'than': 1, '350,000': 1, 'words': 1, 'meanings,': 1, 'curated': 1, 'annotated': 1, 'by': 1, 'our': 1, 'expert': 1, 'lexicographers.': 1}, 86)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### Dealing with Internet searches","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\npath_to_Internet_search = '/kaggle/input/saeyvly7-csv/saeyvlY7.csv'\ndf = pd.read_csv(path_to_Internet_search)\n\ndef compute_interest_emb(arr, alpha=0.01, prev_idx=None, previous_emb=None):\n    \"\"\"\n    Compute the emb for interest of the user based on Internet search using EMA\n    \n    Args:\n        df: DataFrame that have 4 columns \n            (Input URL, Title, Meta Description, Meta Keywords)\n        alpha (float): hyperparameter for EMA\n        prev_idx (int): index of the last computed interest\n        prev_emb (numpy.ndarray): last computed interest\n        \n    Returns:\n        numpy.ndarray (n,): n is the total number of vocabularies in the dictionary,\n                            showing correlation with each vocab\n    \"\"\"\n    \n    # df = df.to_numpy() # for faster inference\n\n    cnt = 0\n    cur_idx = prev_idx+1 if prev_idx else 0\n    interest_emb = previous_emb if previous_emb else np.zeros(1024)\n\n    for idx, search in enumerate(arr[cur_idx:]):\n        interest = search\n        # we concatinate Title, Meta Description, Meta Keywords if exists\n        # for j in range(1, 4):\n        #     try:\n        #         pass\n        #         if not np.isnan(search[j]):\n        #             interest += search[j]\n        #     except:\n        #         interest += search[j]\n        if (len(interest)<50): continue\n        # print(interest)\n        cnt += 1\n\n        interest_emb = (1-alpha)*interest_emb + \\\n                            alpha*calc_text_embedding(interest, tokenizer).detach().cpu().numpy()\n        \n        # interest_emb = interest_emb/(1-alpha**(idx+1))\n        # interest_emb = interest_emb.squeeze() # (1024,)\n        # print(interest_emb.shape)\n\n    interest_emb = interest_emb.squeeze() \n    interest_emb = interest_emb/(1-alpha**(cnt+1))\n    return interest_emb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:47.443868Z","iopub.execute_input":"2024-12-30T05:20:47.444078Z","iopub.status.idle":"2024-12-30T05:20:47.720024Z","shell.execute_reply.started":"2024-12-30T05:20:47.444049Z","shell.execute_reply":"2024-12-30T05:20:47.719340Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### Combine everything","metadata":{}},{"cell_type":"code","source":"\n\nbio = \"\"\"\nMy profession and expertise are in UX/UI Designer, where I focus on Human-computer interaction,\n sustainable technology, and indie video game development. At 29 years old, I enjoy spending my free time on Digital painting, hiking, and playing board games, \n which help me unwind and stay inspired. I identify as Non-binary, and I am deeply passionate about Human-computer interaction, sustainable technology, and indie video game development\n , which drive much of my professional and personal growth. \n These interests fuel my curiosity and commitment to making a positive impact in my work and beyond.\n\"\"\"\n\nsentence = \"\"\"technology technology technology technology technology technology In this example, we walk through how you can combine retrieval results from multiple queries and multiple indexes.\nThe retrieved nodes will be reranked according to the Reciprocal Rerank Fusion algorithm demonstrated in this paper. It provides an effecient method for rerranking retrieval results without excessive computation or reliance on external models.\nA dictionary dataset that reflects American English as it's used today. The machine-readable format of the New Oxford American Dictionary provides more than 350,000 words and meanings, curated and annotated by our expert lexicographers.\"\"\"\n\nhistory = [\"Storage removeItem() MethodWell organized and easy to understand Web building tutorials with lots of examples of how to use HTML, CSS, JavaScript, SQL, Python, PHP, Bootstrap, Java, XML and more.HTML, Python, CSS, SQL, JavaScript, How to, PHP, Java, C, C++, C#, jQuery, Bootstrap, Colors, W3.CSS, XML, MySQL, Icons, NodeJS, React, Graphics, Angular, R, AI, Git, Data Science, Code Game, Tutorials, Programming, Web Development, Training, Learning, Quiz, Exercises, Courses, Lessons, References, Examples, Learn to code, Source code, Demos, Tips, Website\",\n\"Imagine Dragons x J.I.D - Enemy (Live from Montreal 2022) - YouTubeImagine Dragons x J.I.D - Enemy (from the series Arcane League of Legends) [Live from Montreal 2022]Listen to “Enemy” from the new album “Mercury - Acts 1 & ...Imagine, Dragons, JID, Arcane, League, Legends, Enemy, (Live, From, Montreal), KIDinaKORNER/Interscope, Records, Alternative\",\n\"Weighted Boxes Fusion in Object Detection - Enhancing AccuracyWeighted boxes Fusion excels as an effective and efficient post-processing step as compared to the traditional Non-Maximum Suppression in object detection.intersection over union,non-maximum suppression,weighted boxes fusion\",\n\"Weighted Boxes Fusion in Object Detection - Enhancing AccuracyWeighted boxes Fusion excels as an effective and efficient post-processing step as compared to the traditional Non-Maximum Suppression in object detection.intersection over union,non-maximum suppression,weighted boxes fusion\",\n\"Where can I download english dictionary database in a text format? - Stack Overflow\",\n\"reactjs - Routes not working properly in React using Vite (ON BUILD) - Stack Overflow\",\n\"How to build and deploy with Vite JS - YouTubeWhat Is Vite? Vite is the French word for fast and is a Javascript development server and bundler that delivers source files over ESM or ES6 modules making i...front-end tooling, javascript es modules, vite js, webpack, webpack dev server\"]\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:47.720754Z","iopub.execute_input":"2024-12-30T05:20:47.721009Z","iopub.status.idle":"2024-12-30T05:20:47.725226Z","shell.execute_reply.started":"2024-12-30T05:20:47.720988Z","shell.execute_reply":"2024-12-30T05:20:47.724485Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\ndef get_k_questions(history, bio, corpus, scores, k = 20):\n    interest_emb = compute_interest_emb(history) # (n, 1024)\n    sim_interest = np.dot(WORD_EMBEDDINGS, interest_emb)\n    \n    # calc bio similarity with each word\n    bio_emb = calc_text_embedding(bio, tokenizer).squeeze().detach().cpu().numpy()\n    sim_bio = np.dot(WORD_EMBEDDINGS, bio_emb)\n    \n    # calc sentence similarity with each word\n    # sent_emb = calc_text_embedding(sentence, tokenizer).squeeze().detach().cpu().numpy()\n    # sim_sent = np.dot(WORD_EMBEDDINGS, sent_emb)\n    \n    # count unique words for the learning sentence\n    word_count, num_word = count_unique_words(corpus)\n    \n    final_score = []\n    \n    w_bio, w_freq, w_history = 0.3, 0.6, 0.3\n    \n    arr = w_bio*sim_bio + w_history*sim_interest\n    \n    for idx in range(len(WORD_EMBEDDINGS)):\n        try:\n            freq_bonus = word_count[WORD_MAPPING[idx][0].lower()]/num_word if WORD_MAPPING[idx][0].lower() in word_count.keys() else 0\n        except:\n            freq_bonus = 0\n        tmp_score = arr[idx] + w_freq*freq_bonus\n        final_score.append(tmp_score)\n    \n    idx = np.argsort(final_score)[::-1]\n\n    idx1 = idx[:k]\n    idx2 = np.copy(idx[k:4*k])\n    np.random.shuffle(idx2)\n\n    score = [final_score[i] for i in idx1]\n    word = [WORD_MAPPING[i][0] for i in idx1]\n    definition = [WORD_MAPPING[i][3] for i in idx1]\n\n    wrong_word = [WORD_MAPPING[i][0] for i in idx2]\n    # wrong_defination = [WORD_MAPPING[i][3] for i in idx2]\n    \n    # wrong_definition = 0\n    res = []\n    for i in range(len(word)):\n        question = {}\n        question[\"word_id\"] = int(idx1[i])\n        question[\"question\"] = definition[i]\n        question[\"answers\"] = wrong_word[i*3:i*3+3]+[word[i]]\n        np.random.shuffle(question[\"answers\"])\n        question[\"correct_id\"] = question[\"answers\"].index(word[i])\n        res.append(question)\n\n    return res\n        # print(word[i],\": \", definition[i])\n\n    # for score,word in final_score[:20]:\n    \n    #     print(f\"{word}: {score:.4f}\")\n\nget_k_questions(history, bio, sentence, [])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:47.726035Z","iopub.execute_input":"2024-12-30T05:20:47.726263Z","iopub.status.idle":"2024-12-30T05:20:48.709577Z","shell.execute_reply.started":"2024-12-30T05:20:47.726244Z","shell.execute_reply":"2024-12-30T05:20:48.708627Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[{'word_id': 156386,\n  'question': '\"Industrial science; the science of systematic knowledge of the industrial arts  especially of the more important manufactures as spinning weaving metallurgy etc.\"',\n  'answers': ['Resuming', 'Stager', 'Technology', 'Resumed'],\n  'correct_id': 2},\n {'word_id': 31294,\n  'question': '\"A conceptualist.\"',\n  'answers': ['Conceptionalist', 'Swinker', 'Student', 'Woman'],\n  'correct_id': 0},\n {'word_id': 41774,\n  'question': '\"of Design\"',\n  'answers': ['Designed', 'Emulatress', 'Foremother', 'Our'],\n  'correct_id': 0},\n {'word_id': 41775,\n  'question': '\"of Design\"',\n  'answers': ['Twitching', 'Painter', 'Designing', 'Designer'],\n  'correct_id': 2},\n {'word_id': 86822,\n  'question': '\"A painter of landscapes.\"',\n  'answers': ['Homiform', 'Landscapist', 'This', 'Architectress'],\n  'correct_id': 1},\n {'word_id': 41806,\n  'question': '\"Intriguing; artful; scheming; as  a designing man.\"',\n  'answers': ['Loresman', 'Touch', 'Mechanic', 'Designing'],\n  'correct_id': 3},\n {'word_id': 52030,\n  'question': '\"of Engineer\"',\n  'answers': ['Engineering', 'Imagery', 'Johnadreams', 'Human'],\n  'correct_id': 0},\n {'word_id': 52029,\n  'question': '\"of Engineer\"',\n  'answers': ['Engineered', 'Painting', 'Linguist', 'Introductress'],\n  'correct_id': 0},\n {'word_id': 28945,\n  'question': '\"A fellow adventurer.\"',\n  'answers': ['We', 'Coadventurer', 'Term', 'Landskip'],\n  'correct_id': 1},\n {'word_id': 89440,\n  'question': '\"A painter; an artist\"',\n  'answers': ['Ancestress', 'Limner', 'Motive', 'Mannish'],\n  'correct_id': 1},\n {'word_id': 151043,\n  'question': '\"A student.\"',\n  'answers': ['Architector', 'Studier', 'Semimute', 'Gome'],\n  'correct_id': 1},\n {'word_id': 75412,\n  'question': '\"An imagined space having more than three dimensions.\"',\n  'answers': ['Were', 'Hyperspace', 'Undertaking', 'Demigoddess'],\n  'correct_id': 1},\n {'word_id': 84595,\n  'question': '\"A younger person.\"',\n  'answers': ['Architect', 'Junior', 'Carte de visite', 'Inhabitress'],\n  'correct_id': 1},\n {'word_id': 23645,\n  'question': '\"A visiting card.\"',\n  'answers': ['Lithotint', 'Carte de visite', 'Feminine', 'Architect'],\n  'correct_id': 1},\n {'word_id': 148664,\n  'question': '\"A portrait.\"',\n  'answers': ['Statue', 'Histrion', 'Draughtsmanship', 'Twitched'],\n  'correct_id': 0},\n {'word_id': 52026,\n  'question': '\"A person skilled in the principles and practice of any branch of engineering. See under Engineering  n.\"',\n  'answers': ['Designing', 'Feme', 'Novelette', 'Engineer'],\n  'correct_id': 3},\n {'word_id': 108507,\n  'question': '\"An artist who represents objects or scenes in color on a flat surface  as canvas plaster or the like.\"',\n  'answers': ['Handcraftsman', 'Lyric', 'Typo', 'Painter'],\n  'correct_id': 3},\n {'word_id': 75770,\n  'question': '\"An image or representation; a portrait or pretended portrait.\"',\n  'answers': ['Juvenal', 'And', 'Icon', 'Adolescent'],\n  'correct_id': 2},\n {'word_id': 9312,\n  'question': '\"An association for promoting art (esp. the arts of design)  and giving encouragement to artists.\"',\n  'answers': ['Art union', 'Interpretation', 'Academist', 'Iconographer'],\n  'correct_id': 0},\n {'word_id': 8400,\n  'question': '\"An archaeologist.\"',\n  'answers': ['Retrait', 'Bonnibel', 'Archaeologian', 'Mulier'],\n  'correct_id': 2}]"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# import time\n# cnt = 0\n# while True:\n#     time.sleep(60)\n#     cnt += 1\n#     print(cnt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:48.710467Z","iopub.execute_input":"2024-12-30T05:20:48.710704Z","iopub.status.idle":"2024-12-30T05:20:48.714138Z","shell.execute_reply.started":"2024-12-30T05:20:48.710677Z","shell.execute_reply":"2024-12-30T05:20:48.713360Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\ndef fetch_meta_data(urls):\n    \"\"\"\n    Fetch title, keywords, and description meta tags for a list of URLs.\n    :param urls: List of URLs to process\n    :return: A dictionary with URL as key and metadata as value\n    \"\"\"\n    metadata = {}\n    \n    for url in urls:\n        try:\n            response = requests.get(url, timeout=10)\n            response.raise_for_status()\n            \n            # Parse the HTML content\n            soup = BeautifulSoup(response.text, 'html.parser')\n            \n            # Extract <title>, <meta name=\"keywords\">, and <meta name=\"description\">\n            title = soup.title.string if soup.title else \"No title tag found\"\n            keywords = soup.find(\"meta\", attrs={\"name\": \"keywords\"})\n            description = soup.find(\"meta\", attrs={\"name\": \"description\"})\n            \n            metadata[url] = {\n                \"title\": title.strip() if title else None,\n                \"keywords\": keywords[\"content\"].strip() if keywords and \"content\" in keywords.attrs else None,\n                \"description\": description[\"content\"].strip() if description and \"content\" in description.attrs else None\n            }\n        \n        except Exception as e:\n            metadata[url] = {\"error\": str(e)}\n    \n    return metadata\n\ndef get_meta_strings(urls):\n    metadata = fetch_meta_data(urls)\n    res = []\n    for _, data in metadata.items():\n        if ('error' in data): continue\n        sentence = \"\"\n        if (data[\"title\"]): sentence += data[\"title\"] + \"; \"\n        if (data[\"keywords\"]): sentence += data[\"keywords\"] + \"; \"\n        if (data[\"description\"]): sentence += data[\"description\"] + \"; \"\n        res.append(sentence)\n    return res\n\nget_meta_strings([\"https://stackoverflow.com/questions/76466982/getting-secretorprivatekey-must-have-a-value-error-in-nestjs-jwt-authenticatio\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:48.714949Z","iopub.execute_input":"2024-12-30T05:20:48.715165Z","iopub.status.idle":"2024-12-30T05:20:49.179183Z","shell.execute_reply.started":"2024-12-30T05:20:48.715146Z","shell.execute_reply":"2024-12-30T05:20:49.178347Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[\"node.js - Getting 'secretOrPrivateKey must have a value' error in NestJS JWT authentication - Stack Overflow; \"]"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"def bio_to_string(bio):\n    res = f\"My profession and expertise are in {bio.occupation}, where I focus on {bio.interests}. At {bio.age} years old, I enjoy spending my free time on {bio.hobbies},which help me unwind and stay inspired. I identify as {bio.gender}, and I am deeply passionate about {bio.interests}, which drive much of my professional and personal growth. These interests fuel my curiosity and commitment to making a positive impact in my work and beyond. Recommend me some definition that I want.\"\n    return res","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:49.180119Z","iopub.execute_input":"2024-12-30T05:20:49.180637Z","iopub.status.idle":"2024-12-30T05:20:49.184242Z","shell.execute_reply.started":"2024-12-30T05:20:49.180598Z","shell.execute_reply":"2024-12-30T05:20:49.183424Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/ngrok.yml\nregion: ap\nversion: '2'\nauthtoken: 1aR1ZEIEYBFQWEinFBasQZGtwCf_641W539xcfewjXC6q6iRW\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:49.185056Z","iopub.execute_input":"2024-12-30T05:20:49.185283Z","iopub.status.idle":"2024-12-30T05:20:49.202524Z","shell.execute_reply.started":"2024-12-30T05:20:49.185252Z","shell.execute_reply":"2024-12-30T05:20:49.201910Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/ngrok.yml\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import nest_asyncio\nfrom pyngrok import ngrok, conf\nimport uvicorn\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom typing import List\n\nfrom pydantic import BaseModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:49.203386Z","iopub.execute_input":"2024-12-30T05:20:49.203667Z","iopub.status.idle":"2024-12-30T05:20:49.514317Z","shell.execute_reply.started":"2024-12-30T05:20:49.203641Z","shell.execute_reply":"2024-12-30T05:20:49.513444Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"conf.get_default().config_path = '/kaggle/ngrok.yml'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:49.517057Z","iopub.execute_input":"2024-12-30T05:20:49.517270Z","iopub.status.idle":"2024-12-30T05:20:49.520688Z","shell.execute_reply.started":"2024-12-30T05:20:49.517252Z","shell.execute_reply":"2024-12-30T05:20:49.519887Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"\n\nclass Bio(BaseModel):\n    gender: str\n    age: int\n    occupation: str\n    hobbies: str\n    interests: str\n\nclass WordScore(BaseModel):\n    word_id: int\n    score: float\n\n\nclass Item(BaseModel):\n    historyUrls: List[str]\n    bio: Bio\n    corpus: str\n    confScores: List[WordScore]\n\napp = FastAPI()\n\n# middlewares\napp.add_middleware(\n    CORSMiddleware, # https://fastapi.tiangolo.com/tutorial/cors/\n    allow_origins=['*'], # wildcard to allow all, more here - https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Origin\n    allow_credentials=True, # https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Credentials\n    allow_methods=['*'], # https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Methods\n    allow_headers=['*'], # https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Headers\n)\n\n@app.get('/')\nasync def root():\n    return {'hello': 'world'}\n\n@app.post(\"/question\")\nasync def get_question(body: Item):\n    # print(get_meta_strings(body.historyUrls))\n    # print(bio_to_string(body.bio))\n    # print(body.corpus)\n    if len(body.historyUrls)>10: body.historyUrls = body.historyUrls[:10]\n    return get_k_questions(get_meta_strings(body.historyUrls), bio_to_string(body.bio), body.corpus, body.confScores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:49.521844Z","iopub.execute_input":"2024-12-30T05:20:49.522103Z","iopub.status.idle":"2024-12-30T05:20:49.540751Z","shell.execute_reply.started":"2024-12-30T05:20:49.522083Z","shell.execute_reply":"2024-12-30T05:20:49.540135Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"\n# ngrok.set_auth_token(\"2l8t1Mz1kYLNPBUaPC01nYmC9zn_877NmhUjsS9c2zpDLDGg2\")\n# specify a port\nport = 8000\n# ngrok_tunnel = ngrok.connect(pyngrok_config=config, name=\"abc\")\nngrok_tunnel = ngrok.connect(port)\nprint(ngrok_tunnel)\n\n# where we can visit our fastAPI app\nprint('Public URL:', ngrok_tunnel.public_url)\n\n\nnest_asyncio.apply()\n\n# finally run the app\nuvicorn.run(app, port=port)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T05:20:49.541661Z","iopub.execute_input":"2024-12-30T05:20:49.541917Z"}},"outputs":[{"name":"stdout","text":"                                                                                                    \r","output_type":"stream"},{"name":"stderr","text":"INFO:     Started server process [40]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n","output_type":"stream"},{"name":"stdout","text":"NgrokTunnel: \"https://8510-34-82-193-114.ngrok-free.app\" -> \"http://localhost:8000\"\nPublic URL: https://8510-34-82-193-114.ngrok-free.app\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"GET / HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"GET / HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"GET / HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     125.235.209.24:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     125.235.209.24:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\nINFO:     2401:d800:f9af:b41e:bc4c:c4d8:efd0:823d:0 - \"POST /question HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# bio = \"My profession and expertise are in UX/UI Designer, where I focus on Human-computer interaction, sustainable technology, and indie video game development. At 29 years old, I enjoy spending my free time on Digital painting, hiking, and playing board games,which help me unwind and stay inspired. I identify as Non-binary, and I am deeply passionate about Human-computer interaction, sustainable technology, and indie video game development, which drive much of my professional and personal growth. These interests fuel my curiosity and commitment to making a positive impact in my work and beyond.\"\n# history = [\"node.js - Getting 'secretOrPrivateKey must have a value' error in NestJS JWT authentication - Stack Overflow; \"]\n# corpus = \"technology technology technology technology technology technology In this example, we walk through how you can combine retrieval results from multiple queries and multiple indexes. The retrieved nodes will be reranked according to the Reciprocal Rerank Fusion algorithm demonstrated in this paper. It provides an effecient method for rerranking retrieval results without excessive computation or reliance on external models. A dictionary dataset that reflects American English as it's used today. The machine-readable format of the New Oxford American Dictionary provides more than 350,000 words and meanings, curated and annotated by our expert lexicographers.\"\n# get_k_questions(history, bio, corpus)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}